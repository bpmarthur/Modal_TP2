{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b358ca1d-39a9-4137-b178-971b768d8ead",
   "metadata": {},
   "source": [
    "# Lab 2: Graph visualization in Python\n",
    "\n",
    "\n",
    "## Installing libraries then restarting jupyter\n",
    "\n",
    "Before starting the lab, please install the following libraries: ipysigma, networkx, numpy, scikit-learn. \n",
    "\n",
    "After restart jupyter and continue the lab.\n",
    "\n",
    "## Graph library in Python: NetworkX\n",
    "We have seen many community detection algorithms today! Let's\n",
    "test them on a real graph. \n",
    "\n",
    "1. Please check this tutorial and try to make a simple graph: https://networkx.org/documentation/stable/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1257ad2f-2d94-4a52-9d47-391af048189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from ipysigma import Sigma\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75479fc6-314e-4657-abe0-264f7d821741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Construct a simple graph of 5 nodes and connect those 5 nodes with 7 edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c238e60-e7b3-43a8-89c0-76f98ca14cc1",
   "metadata": {},
   "source": [
    "### Game of Thrones character interaction\n",
    "You will find in the TP archive a dataset about the interaction of the characters in Game of Thrones, per season. Create a NetworkX graph from one of the seasons (e.g. season 1), adding also the weight of edges. Check if you have created if you created correctly the graph, for example like this:\n",
    "\n",
    "print(G.number_of_nodes())\n",
    "\n",
    "print(G.number_of_edges())\n",
    "\n",
    "print(G.adj['NED']) # for the first season\n",
    "\n",
    "For reading or writing a csv file, you can use the python csv library we saw last time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c0881-6cfa-4695-ba22-0211cc3c883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Game of Thrones graph from the csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46eaf52-5d8d-4740-96f1-ec49f104404e",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "\n",
    "Do the following exercises. Note that if you find the results a bit difficult to evaluate, you can remove less important nodes from the graph (such as nodes that interact with the least amount of other characters).\n",
    "\n",
    "2. Compute communities using:\n",
    "- the Louvain algorithm https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.louvain.louvain_communities.html, \n",
    "- clique percolation https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.kclique.k_clique_communities.html (experiment with different k values)\n",
    "- the Girvan Newman algorithm https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.centrality.girvan_newman.html\n",
    "- and label propagation https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.label_propagation.label_propagation_communities.html\n",
    "3. We could suppose that there is a link between the house of the character (its family) and the community it belongs to. Do we observe this pattern in the previous communities? For this, we can check what are the great houses https://gameofthrones.fandom.com/wiki/Great_House .  \n",
    "4. Create a new graph per season and retrieve the top 10 nodes according to a node centrality measure https://networkx.org/documentation/stable/reference/algorithms/centrality.html . Does the nodes'importance change over the seasons, is it important to observe the evolution of a graph over time?  \n",
    "Plot the results for a few nodes over the seasons using matplotlib. Here is a small tutorial on how to do this: https://www.geeksforgeeks.org/how-to-plot-a-time-series-in-matplotlib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d31b1-2ee2-4ffa-9912-a0875602fda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution for exercises above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96304a1e-3453-4d31-b9a2-f76d243e2b77",
   "metadata": {},
   "source": [
    "## Crawling a website for additional information\n",
    "The dataset you used in the previous exercise is very interesting, but the nodes have very little information. However, we can find more information online about each character, if we follow the link assigned to each node. Each link get us to a webpage with a lot of information about this character. \n",
    "Let's crawl more information using the BeautifulSoup library that we saw last time. \n",
    "\n",
    "### Exercise\n",
    "5. Write a function that given the page of a character, gets the content of the tag meta property=\"og:description\". To understand better where the tag comes from, read about the Open Graph Protocol: https://ogp.me/\n",
    "For example, for Jon Snow we want to retrieve the following content. Note that the description might be missing for some characters. \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f36a02f9-d12e-4cd8-b6d2-8aa1f78d66d0",
   "metadata": {},
   "source": [
    "<meta property=\"og:description\" content=\"Jon Snow, born Aegon Targaryen, is the son of Lyanna Stark and Rhaegar Targaryen, the late Prince of Dragonstone. From infancy, Jon is presented as the bastard son of Lord Eddard Stark, Lyanna's brother, and raised alongside Eddard's lawful children at Winterfell. Jon's true parentage is kept secret from everyone, including Jon himself, in order to protect him from those that sought the complete annihilation of House Targaryen. Jon joins the Night's Watch and is later elected as Lord Commander. \"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99432f0-7b1b-4cdc-894d-59cc298549e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution for the Exercise 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a773bac4-3e00-47fb-b9e9-9d3846fbc8d8",
   "metadata": {},
   "source": [
    "### Kmeans and TFIDF\n",
    "\n",
    "We now have a data graph, let's try to run k-means on it. First let's see an example on how to do it! We will use the functions \n",
    "- TFIDF for computing a vector representation of text: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "- kmeans for computing a clustering on the vectors obtained: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "- and the silhouette score to see which value of k to choose (we pick the k that maximizes the silhouette score): https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
    "\n",
    "\n",
    "Check the output of the code below! First, see how the TDIDF vectors are computer, when do we have 0 in a dimension?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e099bfdf-b64f-44af-b133-ca1a5c481768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "corpus = [\n",
    "\n",
    "    \"Cats are more independent animals.\",\n",
    "\n",
    "    \"Cats are easiers to take care of.\",\n",
    "\n",
    "    \"Monkeys are very smart.\",\n",
    "\n",
    "    \"Dogs are human's best friend.\",\n",
    "    \n",
    "    \"Dogs are runners.\",\n",
    "\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "a = X.todense()\n",
    "print(a)\n",
    "\n",
    "\n",
    "for k in range(2,len(corpus)):\n",
    "    print(\"number of clusters: \"+ str(k))\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "    print(silhouette_score(X, kmeans.labels_))\n",
    "    print(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9a536-c994-49c8-8a14-e64e763dd843",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "6. Run kmeans on the description of the characters, by keeping only characters for which you could retrieve a description. Find the best k using the silhouette score. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de85920-ba2e-4975-9d04-fafd0754bebf",
   "metadata": {},
   "source": [
    "# Graph visualization in Python\n",
    "Now that we are more familiar with graphs, let's try to visualize them! In the past, we have used Gephi: https://github.com/gephi/gephi\n",
    "It is still an option, however, it is no longer regularly maintained. Given this, in this lab we will explore ipysigma, a visualization library created by Medialab in Sciences Po: https://github.com/medialab/ipysigma Go through the tutorial on the page of the ipysigma library.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca9b472-b323-4dca-b45d-1efd1f9c77b4",
   "metadata": {},
   "source": [
    "### Citation graph visualization in ipysigma\n",
    "In networkx we can create graphs ourselves, but we can also read it from the disk - for example from a CSV file as you saw before, but also from files in the format gexf. Read more about it here: https://networkx.org/documentation/stable/reference/readwrite/gexf.html  In the TP we share a graph in this format called Decodex. It was created by Le Monde and contains information about news websites, their level of reliability and how they cite each other. For example, Le Monde is a node in this graph, with the properties seen below. The graph contains also edges with weights, with the source node being the citing website and the target note the cited website.\n",
    "\n",
    "You can find it yourself if you open the file in a text editor. You will observe that it is written in XML, a format that is similar to HTML. \n",
    "The nodes in this graph can have the reliability score of [\"Parodique\", \"Douteux\", \"Peu fiable\", \"Plutôt fiable\"] "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a440a6c2-eebd-46f1-9853-82bb50d71b2e",
   "metadata": {},
   "source": [
    " <node id=\"8ecdecba-1cf2-482e-a3a4-9dd3fb3e8a32\" label=\"Le Monde\">\n",
    "        <attvalues>\n",
    "          <attvalue for=\"catégorie\" value=\"Média français\"></attvalue>\n",
    "          <attvalue for=\"attr_status\" value=\"IN\"></attvalue>\n",
    "          <attvalue for=\"attr_modification\" value=\"1498556446\"></attvalue>\n",
    "          <attvalue for=\"decodex\" value=\"4\"></attvalue>\n",
    "          <attvalue for=\"orientation contenu\" value=\"Autre ou non déterminé\"></attvalue>\n",
    "          <attvalue for=\"fiabilité\" value=\"Plutôt fiable\"></attvalue>\n",
    "          <attvalue for=\"description\" value=\"Un quotidien et site Internet d'information généraliste. Le groupe est détenu depuis 2010 par les hommes d'affaires Xavier Niel, Pierre Bergé et Matthieu Pigasse.\"></attvalue>\n",
    "          <attvalue for=\"attr_home\" value=\"http://youtube.com/channel/UCYpRDnhk5H8h16jpS84uqsA\"></attvalue>\n",
    "          <attvalue for=\"concat\" value=\"Plutôt fiable - Média français - Autre ou non déterminé\"></attvalue>\n",
    "          <attvalue for=\"synthèse\" value=\"Média français plutôt fiable\"></attvalue>\n",
    "          <attvalue for=\"fiabilité et orientation\" value=\"Plutôt fiable\"></attvalue>\n",
    "        </attvalues>\n",
    "      </node>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167285a-5a79-47c4-82be-670360353b5a",
   "metadata": {},
   "source": [
    "### Creating node partitions and using colors for analysis\n",
    "\n",
    "Below we show how to create a complex visualization using ipysigma. We first partition the nodes according to their reliability (fiabilité) and also we give them colors according to the same attribute. \n",
    "Then we give edges colors according to the color of the target node. We position the nodes according to the partitions they belong to.\n",
    "Like this, we can see how communities cite each other. We also set the size of the nodes to be proportional to their Pagerank score.\n",
    "Note that the library is under development and sometimes the documentation might not be sufficiently clear. Try looking if your problem is also not mentioned in the issues of the libraries on Github: https://github.com/medialab/ipysigma/issues \n",
    "If you do not see it, but think your code should still be correct according to their instructions, create a new issue!\n",
    "\n",
    "Note that you can click on nodes in the ipysigma visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b8057-f108-4a05-911b-48f000852487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing a gexf graph\n",
    "g = nx.read_gexf('./Decodex.gexf')\n",
    "fiabilite_categories = [\"Parodique\", \"Douteux\", \"Peu fiable\", \"Plutôt fiable\"]\n",
    "colors = {\n",
    "    \"Peu fiable\": \"#E74C3C\",       # Red\n",
    "    \"Douteux\": \"#F1C40F\",    # Yellow\n",
    "    \"Parodique\": \"#2ECC71\",      # Green\n",
    "    \"Plutôt fiable\": \"#3498DB\",  # Blue\n",
    "    \"Unknown\": \"#95A5A6\"\n",
    "    \n",
    "}\n",
    "\n",
    "partitions = {\"Parodique\": [], \"Douteux\": [], \"Peu fiable\": [], \"Plutôt fiable\": []}\n",
    "\n",
    "# Assign colors based on 'fiabilité' attribute (if it exists)\n",
    "for node in g.nodes:\n",
    "    fiabilite = g.nodes[node].get(\"fiabilité\", \"Unknown\")  # Default to \"medium\"\n",
    "    g.nodes[node][\"color_node\"] = colors.get(fiabilite, \"#95A5A6\")  # Gray if unknown\n",
    "    g.nodes[node][\"size\"] = 10  # Set a default size\n",
    "    partitions[fiabilite].append(node)\n",
    "\n",
    "\n",
    "# Assign edge colors based on the target node’s color\n",
    "for source, target in g.edges:\n",
    "    g.edges[source, target][\"color_edge\"] = g.nodes[target][\"color_node\"]\n",
    "\n",
    "\n",
    "layout = {}\n",
    "grid_positions = {\n",
    "    \"Peu fiable\": (-2, -2),\n",
    "     \"Douteux\": (-2, 2),\n",
    "    \"Parodique\": (2, -2),\n",
    "    \"Plutôt fiable\": (2, 2)\n",
    "}\n",
    "\n",
    "for category, nodes in partitions.items():\n",
    "    base_x, base_y = grid_positions[category]\n",
    "    angle_step = 2 * np.pi / max(1, len(nodes)) \n",
    "    radius = 1.5  # Spread out the nodes\n",
    "\n",
    "    for i, node in enumerate(nodes):\n",
    "        angle = i * angle_step\n",
    "        layout[node] = {\n",
    "            \"x\": base_x + radius * np.cos(angle),\n",
    "            \"y\": base_y + radius * np.sin(angle)\n",
    "        }\n",
    "\n",
    "# Visualize with ipysigma\n",
    "sigma = Sigma(\n",
    "    g,\n",
    "    raw_node_color=\"color_node\",\n",
    "    raw_edge_color=\"color_edge\",\n",
    "    layout=layout,\n",
    "    node_label=\"label\",\n",
    "    default_edge_type=\"curve\",\n",
    "    node_border_color_from=\"node\",\n",
    "    label_font=\"cursive\",\n",
    "    node_size=nx.pagerank(g)\n",
    ")\n",
    "\n",
    "sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00ffb5-eac6-404f-9610-e812c25b9a56",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "7. How do reliable sources of information interact with untrusted sources in the Decoders graph, who is citing whom? \n",
    "Give a short explanation based on the above visualization.\n",
    "8. How do the types of information sources interact with each other in the Decoders graph? To observe this, create a similar visualization as the above, but this type using the attribute \"catégorie\".\n",
    "9. How does the citation network look like when we consider the political orientation of the websites? For this use the attribute \"orientation contenu\".\n",
    "10. How does the citation network look like when we use finer partitions, for examples partitions where we have two dimensions, the reliability of the content and the political orientation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba594de-8582-4500-8678-6c4b3b656a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solutions for the exercises above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bbdbf-c389-4e1c-9d06-9bc4ee4372df",
   "metadata": {},
   "source": [
    "\n",
    "## Read a research article that investigates the potential of using modularity to detect polarization\n",
    "\n",
    "You will find on Moodle a research article published at the conference ICWSM https://www.icwsm.org/2025/index.html\n",
    "Take the time to read it and see how researchers test ideas on real applications and propose new metrics when they consider existing tools are not sufficient. In your project you will also have to investigate your hypothesis on the data of your choice! \n",
    "\n",
    "11. After reading the article, implement the notion of boundary described. Apply it on one of the graphs you have seen so far in this class, or on one graph from here (choose smaller graphs for efficiency): http://snap.stanford.edu/data/index.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3625e6-7e53-47ea-aca6-9048046dc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for exercise 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
